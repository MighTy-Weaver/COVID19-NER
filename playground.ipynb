{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "Data format:\n",
    "\n",
    "|id|word_seq|tag_seq|\n",
    "|:--|:--|:--|\n",
    "|index of the sentence|tokenized words|corresponding NER tags|\n",
    "|0|`[\"protection\", \"calves\", ...]`|`[\"O\", \"LIVESTOCK\", ...]`|\n",
    "|1|`[\"prevent\", \"diarrhea\",...]` |`[\"O\", \"DISEASE_OR_SYNDROME\", ...]`|\n",
    "|...|...|...|\n",
    "\n",
    "\n",
    "\n",
    "There are 64 categories of NER tags (plus 1 padding token).\n",
    "\n",
    "The ground-truth tags are provided for the training and testing set, while being omitted in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in train_dict: dict_keys(['id', 'word_seq', 'tag_seq'])\n",
      "keys in val_dict: dict_keys(['id', 'word_seq', 'tag_seq'])\n",
      "keys in test_dict: dict_keys(['id', 'word_seq'])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "train_dict = pkl.load(open(\"data/train.pkl\", \"rb\"))\n",
    "val_dict = pkl.load(open(\"data/val.pkl\", \"rb\"))\n",
    "test_dict = pkl.load(open(\"data/test.pkl\", \"rb\"))\n",
    "print(\"keys in train_dict:\", train_dict.keys())\n",
    "print(\"keys in val_dict:\", val_dict.keys())\n",
    "print(\"keys in test_dict:\", test_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "('Protection', 'O') ('of', 'O') ('calves', 'LIVESTOCK') ('against', 'O') ('fatal', 'O') ('enteric', 'DISEASE_OR_SYNDROME') ('colibacillosis', 'DISEASE_OR_SYNDROME') ('by', 'O') ('orally', 'GENE_OR_GENOME') ('administered', 'GENE_OR_GENOME') ('Escherichia', 'GENE_OR_GENOME') ('coli', 'GENE_OR_GENOME') ('K99', 'GENE_OR_GENOME') ('-', 'O') ('specific', 'CARDINAL') ('monoclonal', 'CARDINAL') ('antibody', 'CARDINAL') ('.', 'O') ('A', 'O') ('monoclonal', 'CHEMICAL') ('antibody', 'CHEMICAL') ('(', 'O') ('MCA', 'GENE_OR_GENOME') (')', 'O') ('to', 'O') ('enterotoxigenic', 'CHEMICAL') ('Escherichia', 'CHEMICAL') ('coli', 'CHEMICAL') ('K99', 'O') ('antigen', 'O') ('agglutinated', 'O') ('K99+', 'GENE_OR_GENOME') ('enterotoxigenic', 'GENE_OR_GENOME') ('E', 'GENE_OR_GENOME') ('.', 'O') ('coli', 'CHEMICAL') ('strains', 'CHEMICAL') ('B44', 'CHEMICAL') ('(', 'O') ('O9', 'O') (':', 'O') ('K30', 'O') (';', 'O') ('K99', 'O') (';', 'O') ('F41', 'O') (':', 'O') ('H-', 'O') (')', 'O') ('and', 'O') ('B41', 'CHEMICAL') ('(', 'O') ('O101', 'PRODUCT') (':', 'O') ('K99', 'O') (';', 'O') ('F41', 'O') (':', 'O') ('H-', 'O') (')', 'O') ('grown', 'O') ('at', 'O') ('37', 'QUANTITY') ('degrees', 'QUANTITY') ('C', 'O') ('but', 'O') ('not', 'O') ('at', 'O') ('18', 'QUANTITY') ('degrees', 'QUANTITY') ('C.', 'O') ('The', 'O') ('MCA', 'GENE_OR_GENOME') (',', 'O') ('which', 'O') ('was', 'O') ('characterized', 'O') ('as', 'O') ('immunoglobulin', 'GENE_OR_GENOME') ('G1', 'GENE_OR_GENOME') (',', 'O') ('reacted', 'O') ('specifically', 'O') ('with', 'O') ('K99', 'CHEMICAL') ('antigen', 'CHEMICAL') ('in', 'O') ('an', 'O') ('enzyme-linked', 'CHEMICAL') ('immunosorbent', 'CHEMICAL') ('assay', 'CHEMICAL') ('and', 'O') ('precipitated', 'O') ('radiolabeled', 'O') ('K99', 'CHEMICAL') ('antigen', 'CHEMICAL') ('.', 'O') ('A', 'O') ('total', 'O') ('of', 'O') ('45', 'O') ('colostrum', 'CHEMICAL') ('-fed', 'O') ('and', 'O') ('colostrum', 'CHEMICAL') ('-deprived', 'O') ('calves', 'LIVESTOCK') ('were', 'O') ('used', 'O') ('in', 'O') ('three', 'CARDINAL') ('separate', 'O') ('trials', 'O') ('to', 'O') ('determine', 'O') ('whether', 'O') ('the', 'O') ('orally', 'O') ('administered', 'O') ('K99-specific', 'O') ('MCA', 'GENE_OR_GENOME') ('would', 'O') ('prevent', 'O') ('diarrhea', 'DISEASE_OR_SYNDROME') ('caused', 'O') ('by', 'O') ('strain', 'O') ('B44', 'GENE_OR_GENOME')\n"
     ]
    }
   ],
   "source": [
    "# an entry of the dataset\n",
    "print(\"index:\", train_dict[\"id\"][0])\n",
    "print(*zip(train_dict[\"word_seq\"][0], train_dict[\"tag_seq\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of the NER tags: 65\n",
      "all the NER tags: {'GROUP_ATTRIBUTE', 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY', 'HUMAN-CAUSED_PHENOMENON_OR_PROCESS', 'TISSUE', 'CELL_COMPONENT', 'GPE', 'ARCHAEON', 'EXPERIMENTAL_MODEL_OF_DISEASE', 'WORK_OF_ART', 'LAW', 'PRODUCT', 'NORP', 'MONEY', 'LIVESTOCK', 'RESEARCH_ACTIVITY', 'ORGAN_OR_TISSUE_FUNCTION', 'LABORATORY_PROCEDURE', 'CORONAVIRUS', 'DAILY_OR_RECREATIONAL_ACTIVITY', 'LABORATORY_OR_TEST_RESULT', 'SOCIAL_BEHAVIOR', 'WILDLIFE', 'INJURY_OR_POISONING', 'ANATOMICAL_STRUCTURE', 'EVENT', 'SUBSTRATE', 'ORGANISM', 'DATE', 'GENE_OR_GENOME', 'BODY_PART_ORGAN_OR_ORGAN_COMPONENT', 'ORDINAL', 'DIAGNOSTIC_PROCEDURE', 'INDIVIDUAL_BEHAVIOR', 'THERAPEUTIC_OR_PREVENTIVE_PROCEDURE', 'EUKARYOTE', 'VIRAL_PROTEIN', 'PHYSICAL_SCIENCE', 'VIRUS', 'MOLECULAR_FUNCTION', 'FOOD', 'MACHINE_ACTIVITY', 'BODY_SUBSTANCE', 'DISEASE_OR_SYNDROME', 'FAC', 'CHEMICAL', 'CELL_OR_MOLECULAR_DYSFUNCTION', 'IMMUNE_RESPONSE', 'CELL', 'QUANTITY', 'CELL_FUNCTION', 'O', 'ORG', 'GROUP', 'CARDINAL', 'EVOLUTION', '_t_pad_', 'BACTERIUM', 'LOC', 'EDUCATIONAL_ACTIVITY', 'MATERIAL', 'LANGUAGE', 'TIME', 'PERSON', 'PERCENT', 'SIGN_OR_SYMPTOM'}\n"
     ]
    }
   ],
   "source": [
    "# all the NER tags:\n",
    "from itertools import chain\n",
    "print(\"count of the NER tags:\", len(set(chain(*train_dict[\"tag_seq\"]))))\n",
    "print(\"all the NER tags:\", set(chain(*train_dict[\"tag_seq\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of word vocab: 82275 size of tag_dict: 65\n"
     ]
    }
   ],
   "source": [
    "# prepare word vocab and tag vocab\n",
    "\n",
    "vocab_dict = {'_unk_': 0, '_w_pad_': 1}\n",
    "\n",
    "for doc in train_dict['word_seq']:\n",
    "    for word in doc:\n",
    "        if(word not in vocab_dict):\n",
    "            vocab_dict[word] = len(vocab_dict)\n",
    "\n",
    "tag_dict = {'_t_pad_': 0} # add a padding token\n",
    "\n",
    "for tag_seq in train_dict['tag_seq']:\n",
    "    for tag in tag_seq:\n",
    "        if(tag not in tag_dict):\n",
    "            tag_dict[tag] = len(tag_dict)\n",
    "word2idx = vocab_dict\n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "tag2idx = tag_dict\n",
    "idx2tag = {v:k for k,v in tag2idx.items()}            \n",
    "\n",
    "print(\"size of word vocab:\", len(vocab_dict), \"size of tag_dict:\", len(tag_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length of a sentence is set to 128\n",
    "max_sent_length = 128\n",
    "\n",
    "train_tokens = np.array([[word2idx[w] for w in doc] for doc in train_dict['word_seq']])\n",
    "val_tokens = np.array([[word2idx.get(w, 0) for w in doc] for doc in val_dict['word_seq']])\n",
    "test_tokens = np.array([[word2idx.get(w, 0) for w in doc] for doc in test_dict['word_seq']])\n",
    "\n",
    "\n",
    "train_tags = [[tag2idx[t] for t in t_seq] for t_seq in train_dict['tag_seq']]\n",
    "train_tags = np.array([to_categorical(t_seq, num_classes=len(tag_dict)) for t_seq in train_tags])\n",
    "\n",
    "val_tags = [[tag2idx[t] for t in t_seq] for t_seq in val_dict['tag_seq']]\n",
    "val_tags = np.array([to_categorical(t_seq, num_classes=len(tag_dict)) for t_seq in val_tags])\n",
    "\n",
    "# we don't have test tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (23600, 128) tag size: (23600, 128, 65)\n",
      "validating size: (2950, 128) tag size: (2950, 128, 65)\n"
     ]
    }
   ],
   "source": [
    "print(\"training size:\", train_tokens.shape, \"tag size:\", train_tags.shape)\n",
    "print(\"validating size:\", val_tokens.shape, \"tag size:\", val_tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  9 10 11] [1 1 2 1 1 3 3 1 4 4]\n"
     ]
    }
   ],
   "source": [
    "# an example of training instance and training tags.\n",
    "print(train_tokens[0,:10], np.argmax(train_tags[0, :10, :], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two simple models and codes for evaluation\n",
    "\n",
    "1. Predict all the tags as \"O\".\n",
    "2. Random guess\n",
    "\n",
    "You could use the `calc_accuracy` function to evaluate the accuracy of your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided function to test accuracy\n",
    "# You could check the validation accuracy to select the best of your models\n",
    "def calc_accuracy(preds, tags, padding_id=\"_t_pad_\"):\n",
    "    \"\"\"\n",
    "        Input:\n",
    "            preds (np.narray): (num_data, length_sentence)\n",
    "            tags  (np.narray): (num_data, length_sentence)\n",
    "        Output:\n",
    "            Proportion of correct prediction. The padding tokens are filtered out.\n",
    "    \"\"\"\n",
    "    preds_flatten = preds.flatten()\n",
    "    tags_flatten = tags.flatten()\n",
    "    non_padding_idx = np.where(tags_flatten!=padding_id)[0]\n",
    "    \n",
    "    return sum(preds_flatten[non_padding_idx]==tags_flatten[non_padding_idx])/len(non_padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "baseline 1, make all predictions as 1. Acc: 0.7562260387120905\n",
      "baseline 2, Random guess. Acc: 0.015637242626076544\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy on the training set\n",
    "train_tags_by_idx = np.argmax(train_tags, axis=2)\n",
    "train_labels = np.array([[idx2tag[p] for p in preds] for preds in train_tags_by_idx])\n",
    "\n",
    "print(calc_accuracy(train_labels, train_labels))\n",
    "\n",
    "# Predict all labels as \"O\"\n",
    "baseline1_train_preds = np.array([[idx2tag[p] for p in preds] for preds in np.ones(train_labels.shape)])\n",
    "print(\"baseline 1, make all predictions as 1. Acc:\", \n",
    "      calc_accuracy(baseline1_train_preds, \n",
    "                    train_labels))\n",
    "\n",
    "# Randomly guess labels.\n",
    "baseline2_train_preds = np.array([[idx2tag[p] for p in preds] for preds in np.random.randint(1, len(tag_dict), train_labels.shape)]) \n",
    "print(\"baseline 2, Random guess. Acc:\", \n",
    "      calc_accuracy(baseline2_train_preds,\n",
    "                    train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output format\n",
    "\n",
    "In this project, you should predict the NER tags for the test set tokens.\n",
    "\n",
    "The index of test set starts from 0 and ends with 2949.\n",
    "\n",
    "You should write the predictions into a .csv file, where the first column is the test indexes in ascending order, and the second column is a json format prediction list.\n",
    "\n",
    "E.g.\n",
    "\n",
    "|id|labels|\n",
    "|:--:|:--:|\n",
    "|0|`['O', 'O', 'CHEMICAL', 'VIRUS', ...]`|\n",
    "|1|`['O', 'O', 'GENE_OR_GENOME', ...]`|\n",
    "|...|...|\n",
    "\n",
    "Format requirements:\n",
    "1. The first column `id` should be an integer, in ascending order, starting from 0 and corresponding to the index in test_dict.\n",
    "2. The second column `labels` should be a dumped string using json, storing the your predictions for each token. The size of the list should be exactly 128, including padding tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For example, this is your prediction for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2950, 128)\n",
      "['HUMAN-CAUSED_PHENOMENON_OR_PROCESS' 'VIRUS' 'SOCIAL_BEHAVIOR'\n",
      " 'BODY_PART_ORGAN_OR_ORGAN_COMPONENT' 'ORGAN_OR_TISSUE_FUNCTION' 'GROUP'\n",
      " 'LANGUAGE' 'SUBSTRATE' 'LANGUAGE' 'PHYSICAL_SCIENCE'\n",
      " 'THERAPEUTIC_OR_PREVENTIVE_PROCEDURE'\n",
      " 'BODY_PART_ORGAN_OR_ORGAN_COMPONENT' 'BODY_PART_ORGAN_OR_ORGAN_COMPONENT'\n",
      " 'MONEY' 'BACTERIUM' 'DIAGNOSTIC_PROCEDURE' 'CELL_FUNCTION'\n",
      " 'LABORATORY_PROCEDURE' 'LABORATORY_OR_TEST_RESULT' 'BACTERIUM'\n",
      " 'RESEARCH_ACTIVITY' 'ORG' 'LAW' 'ORGAN_OR_TISSUE_FUNCTION'\n",
      " 'BODY_SUBSTANCE' 'SOCIAL_BEHAVIOR' 'SOCIAL_BEHAVIOR' 'CELL_FUNCTION'\n",
      " 'NORP' 'MOLECULAR_FUNCTION' 'DISEASE_OR_SYNDROME' 'PRODUCT'\n",
      " 'DAILY_OR_RECREATIONAL_ACTIVITY' 'SUBSTRATE'\n",
      " 'DAILY_OR_RECREATIONAL_ACTIVITY' 'DATE'\n",
      " 'THERAPEUTIC_OR_PREVENTIVE_PROCEDURE' 'DISEASE_OR_SYNDROME' 'BACTERIUM'\n",
      " 'CORONAVIRUS' 'BODY_SUBSTANCE' 'MATERIAL' 'CELL' 'PERSON'\n",
      " 'LABORATORY_OR_TEST_RESULT' 'CORONAVIRUS' 'ANATOMICAL_STRUCTURE'\n",
      " 'EDUCATIONAL_ACTIVITY' 'ORGAN_OR_TISSUE_FUNCTION' 'BODY_SUBSTANCE'\n",
      " 'CARDINAL' 'DAILY_OR_RECREATIONAL_ACTIVITY' 'LIVESTOCK' 'CHEMICAL'\n",
      " 'INDIVIDUAL_BEHAVIOR' 'WILDLIFE' 'CELL_FUNCTION' 'GPE' 'MACHINE_ACTIVITY'\n",
      " 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY' 'GROUP' 'LAW'\n",
      " 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY' 'O' 'VIRAL_PROTEIN' 'LOC'\n",
      " 'ARCHAEON' 'CARDINAL' 'MOLECULAR_FUNCTION' 'SIGN_OR_SYMPTOM' 'SUBSTRATE'\n",
      " 'CORONAVIRUS' 'MONEY' 'QUANTITY' 'GROUP_ATTRIBUTE' 'LAW' 'PERSON' 'ORG'\n",
      " 'EVOLUTION' 'GROUP_ATTRIBUTE' 'LABORATORY_OR_TEST_RESULT' 'GPE' 'TISSUE'\n",
      " 'FAC' 'FAC' 'WILDLIFE' 'GROUP_ATTRIBUTE' 'BACTERIUM' 'PERSON' 'PERCENT'\n",
      " 'DAILY_OR_RECREATIONAL_ACTIVITY' 'ARCHAEON' 'ANATOMICAL_STRUCTURE'\n",
      " 'QUANTITY' 'DIAGNOSTIC_PROCEDURE' 'NORP' 'ANATOMICAL_STRUCTURE'\n",
      " 'EUKARYOTE' 'SOCIAL_BEHAVIOR' 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY'\n",
      " 'VIRAL_PROTEIN' 'INDIVIDUAL_BEHAVIOR' 'MACHINE_ACTIVITY' 'PRODUCT'\n",
      " 'DIAGNOSTIC_PROCEDURE' 'LANGUAGE' 'FAC' 'LANGUAGE' 'PERCENT' 'CHEMICAL'\n",
      " 'CELL_COMPONENT' 'PERSON' 'GENE_OR_GENOME'\n",
      " 'BODY_PART_ORGAN_OR_ORGAN_COMPONENT' 'LAW' 'CORONAVIRUS' 'EVOLUTION'\n",
      " 'QUANTITY' 'ORGAN_OR_TISSUE_FUNCTION' 'WORK_OF_ART' 'ORDINAL' 'PERSON'\n",
      " 'LANGUAGE' 'ORDINAL' 'EDUCATIONAL_ACTIVITY' 'BACTERIUM' 'ORGANISM'\n",
      " 'EDUCATIONAL_ACTIVITY']\n"
     ]
    }
   ],
   "source": [
    "test_preds_numerical = np.random.randint(1, len(tag_dict), \n",
    "                                         (len(test_dict[\"id\"]), max_sent_length))\n",
    "test_preds = np.array([[idx2tag[p] for p in preds] for preds in test_preds_numerical])\n",
    "print(test_preds.shape)\n",
    "print(test_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take the baseline 1 as an example, where we predict all labels as 1.\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': test_dict[\"id\"],\n",
    "                   'labels': [json.dumps(np.array(preds).tolist()) for preds in test_preds]})\n",
    "df.to_csv('test_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[\"HUMAN-CAUSED_PHENOMENON_OR_PROCESS\", \"VIRUS\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[\"LABORATORY_PROCEDURE\", \"EXPERIMENTAL_MODEL_O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[\"MONEY\", \"ARCHAEON\", \"IMMUNE_RESPONSE\", \"LANG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[\"PERSON\", \"GPE\", \"GROUP\", \"LAW\", \"TIME\", \"DAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[\"CHEMICAL\", \"CELL\", \"HUMAN-CAUSED_PHENOMENON_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>2945</td>\n",
       "      <td>[\"DATE\", \"SUBSTRATE\", \"HUMAN-CAUSED_PHENOMENON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>2946</td>\n",
       "      <td>[\"CORONAVIRUS\", \"NORP\", \"EDUCATIONAL_ACTIVITY\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>2947</td>\n",
       "      <td>[\"INDIVIDUAL_BEHAVIOR\", \"FAC\", \"FOOD\", \"SOCIAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>2948</td>\n",
       "      <td>[\"LAW\", \"SIGN_OR_SYMPTOM\", \"CARDINAL\", \"MATERI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>2949</td>\n",
       "      <td>[\"LAW\", \"MONEY\", \"ORDINAL\", \"RESEARCH_ACTIVITY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             labels\n",
       "0        0  [\"HUMAN-CAUSED_PHENOMENON_OR_PROCESS\", \"VIRUS\"...\n",
       "1        1  [\"LABORATORY_PROCEDURE\", \"EXPERIMENTAL_MODEL_O...\n",
       "2        2  [\"MONEY\", \"ARCHAEON\", \"IMMUNE_RESPONSE\", \"LANG...\n",
       "3        3  [\"PERSON\", \"GPE\", \"GROUP\", \"LAW\", \"TIME\", \"DAT...\n",
       "4        4  [\"CHEMICAL\", \"CELL\", \"HUMAN-CAUSED_PHENOMENON_...\n",
       "...    ...                                                ...\n",
       "2945  2945  [\"DATE\", \"SUBSTRATE\", \"HUMAN-CAUSED_PHENOMENON...\n",
       "2946  2946  [\"CORONAVIRUS\", \"NORP\", \"EDUCATIONAL_ACTIVITY\"...\n",
       "2947  2947  [\"INDIVIDUAL_BEHAVIOR\", \"FAC\", \"FOOD\", \"SOCIAL...\n",
       "2948  2948  [\"LAW\", \"SIGN_OR_SYMPTOM\", \"CARDINAL\", \"MATERI...\n",
       "2949  2949  [\"LAW\", \"MONEY\", \"ORDINAL\", \"RESEARCH_ACTIVITY...\n",
       "\n",
       "[2950 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"test_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please make your output-format exactly the same as above\n",
    "\n",
    "You could check it by playing around with the validation set with our evaluation codes `evaluate.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.754806329370245\n"
     ]
    }
   ],
   "source": [
    "# val_preds_numerical = np.random.randint(1, len(tag_dict), \n",
    "#                                          (len(val_dict[\"id\"]), max_sent_length))\n",
    "val_preds = np.array([[idx2tag[p] for p in preds] for preds in np.ones((len(val_dict[\"id\"]), max_sent_length))])\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': val_dict[\"id\"],\n",
    "                   'labels': [json.dumps(np.array(preds).tolist()) for preds in val_preds]})\n",
    "df.to_csv('val_preds.csv', index=False)\n",
    "\n",
    "from evaluate import evaluate\n",
    "\n",
    "print(\"val accuracy\", evaluate('val_preds.csv', \"data/val.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
